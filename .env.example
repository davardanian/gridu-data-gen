# .env.example
# Gemini AI Configuration
# GEMINI_API_KEY=your_gemini_api_key_here

# Vertex AI Configuration (Alternative to API Key)
# Uses Google Application Default Credentials (gcloud CLI authentication)
PROJECT_ID=your-gcp-project-id
LOCATION=us-central1

# Database Configuration
# These variables are used by Docker Compose to create the PostgreSQL instance
# and by the application to construct the database connection URL
DB_HOST=postgres
DB_PORT=5432
DB_NAME=data_assistant
DB_USER=postgres
DB_PASSWORD=password

# Langfuse Configuration
LANGFUSE_PUBLIC_KEY=your_langfuse_public_key
LANGFUSE_SECRET_KEY=your_langfuse_secret_key
LANGFUSE_HOST=https://cloud.langfuse.com

# Application Configuration
APP_ENV=development
LOG_LEVEL=INFO
DEBUG=false

# Data Generation Configuration
DEFAULT_TEMPERATURE=0.2
DEFAULT_RECORDS_PER_TABLE=100
MAX_RECORDS_PER_TABLE=10000
DEFAULT_INSTRUCTIONS=Generate realistic, diverse data that follows common patterns and constraints
# Note: User instructions are optional - if not provided, use DEFAULT_INSTRUCTIONS

# AI Model Configuration
GEMINI_MODEL=gemini-2.5-flash
MAX_OUTPUT_TOKENS=65535
MAX_DATA_GENERATION_TOKENS=65535
MAX_QUERY_GENERATION_TOKENS=1000
DEFAULT_QUERY_TEMPERATURE=0.1
